Python Tricks:

Assertions:
The proper use of assertions is to tell the programmer of the unreoverable errors.
Assertions are not intended to signal expected error conditions, where the user can take corrective actions or can just try again.
Assertions are meant to be internal self checks for your program. They work by declaring some condition as impossible in your code.
If one of these condition doesn't hold that means there is a bug in the program.

Like in below example other than using if statement and raising an exception we can go with assertion.
def apply_discount(product, discount):
    price = int((product['price']) * (1.0 - discount))
    assert 0 <= price <= product['price']
    return price

shoes = {'name':'Fancy Shoes', 'price':14900}
+ive case:
    (apply_discount(shoes, .2) / 100)
-ive case:
    (apply_discount(shoes, 2.0) / 100)

Caveat #1 - Don't use asserts for Data Validation
The biggest caveat with asserts in python is tht assertions can be globally disabled using -O or -OO.
This turns any asserts statement into a null operation which simply gets compiled away and won't be executed.

Caveat #2 - Assert that never fails
Non-Empty tuple is always True in Python.
>>> assert (1==2, 'This should fail')
<stdin>:1: SyntaxWarning: assertion is always true, perhaps remove parentheses?
It will give a warning but never fail.

Key Takeaways:
Python's assert statement is a debugging aid that tests a condition as an internal self check in your program.
Asserts should only be used to help developers identify bugs. They are not a mechanism for handling runtime errors.
Asserts can be globally disabled with an interpreter setting.

Commas are very important in python:
Its always a good practice to keep list, set, dict and tuple multiline.
In case you forgot to add a comma between two items of a list, python will merge it.
>>> ['ab','ms','ch' 'ra'] ## ['ab', 'ms', 'chra']
This 'string literal concatenation' is an intentional and documented behaviour.

Solution: It's all about the habits
    Always place items of list multiline.
    place a comma after each item, even the last item.

Key takeaways:
    Smart formatting and comma placesment can make your list, dict or set constants easy to maintain.
    Python's string literal concatenation feature can work to your benifits or introduce hard to catch bugs.

Context managers and the with statement
The with statement in python is regarded as an obscure feature by some. But when you peek behind the scenes, you'll see that there's no magic involved, and it's actually a highly useful feature that can help you write cleaner and more readable python code.
So what'st he with statement good for? It helps simplify some common resource management patterns by abstracting their functionality and allowing them to be factored out and reused. 
A good way to see this feature used effectively is by looking at examples in the Python standard library. 
The built in open function provides us with an excellent use case:
with open('abc.txt', 'w') as f:
    f.write('hello')

Opening the file using a with statement is generally recommended because it ensures open file descriptors are closed automatically after program execution leaves the context of the with statement. Internally, the above code sample transalates to something like this:
f = open('hello.txt', 'w')
try:
    f.write('hello')
finally:
    f.close()
You can already tell that this is quite a bit verbose. Note that the try.. finally statement is significant. It wouldn't be enough to write something like this:
f = open('hello.txt','w')
f.write('hello')
f.close()
This implementation won't gurantee the file is closed if there's an exception during the f.write() call and therefore our program might leak a file descriptor. That's why the with statement is so useful. It make properly acquiring and releasing resources a breeze.

Using a with statement allows you to abstract away most of the resource handling logic. Instead of having to write explicitly try..finally statement each time, usually the with statement takes care of that for us.
The with statement can make code that deals with system resources more redable. It also helps you avoid bugs or leaks by making it practically impossible to forget to cleanup or release a resource when it's no longer needed.

Supporting 'with' in your own objects:
We can provide the same functionality of open statement with our own classes and functions by implementing so-called context managers.

What's a context manager? It's a simple protocol or interface that your object needs to follow in order to support the with statement.
All you need to do is add two methods:
__enter__ and __exit__ 
to make your class a Context Manager.

class ManagerFile:
    def __init__(self, name):
        self.name = name
    def __enter__(self):
        self.file = open(self.name, 'w')
        return self.file
    def __exit__(self, exc_type, exc_val, ex_tb):
        if self.file:
            self.file.close()

Our ManagerFile class follows the context manager protocol and now support the with statement. just like the original open() example did.
with ManagerFile('open.txt') as f:
    f.write('Hello ji\n')
    f.write('Close yourself\n')

Python calls __enter__ when execution enters the context of the with statement and it's time to acquire the resource. When execution leaves the context again, python calls __exit__ to free up the resource.

Writing a class based context manager is not the only way to support the with statement in python. The contextlib utility module is a standard library which provides a few more abstraction build on the top of basic context manager protocol. This can make your life a little easier if your use case match with what's offered by contextlib.

For example - you can use the contextlib.contextmanager decorator to define a generator based factory function for a resource that will then automatically support the with statement. Here's what rewriting our ManagerFile context manager example with this technique look like:
from contextlib2 import contextmanager
@contextmanager
def manager_file(name):
    try:
        f = open(name, 'w')
        yield f
    finally:
        f.close()
with manager_file('new_open.txt') as f:
    f.write('This is another way of using context manager\n')
    f.write('byebye')

In this case managed_file() is a generator that first acquires the resource. After that, it temporarily suspends its own execution and yields the resource so it can be used by the caller. When the caller leaves the with context, the generator continues to execute so that any remaining clean up steps can occur and the resources can get released back to the system.

The class based implementation and the generator based implementation are essentially equivalent. You might prefer one over the other depending on which approcach you find more readable.

A downside of the @contextmanager based implementation might be that it requires some understanding of advanced python concepts like decorator and generator.

Writing pretty APIs with Context Managers:
Create a timer class with context manager using time().
import time
class MeasureTime: 
        
    def __enter__(self):
        self.start = time.time()
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end = time.time()
        print(self.end - self.start)

with MeasureTime():
    for i in range(10000000):
        pass

Same example using contextlib2 and contextmanager decorator
from contextlib2 import contextmanager

@contextmanager
def time_taken():
    try:
        st = time.time()
        yield st
    finally:
        print(time.time()  - st)

with time_taken():
    for i in range(100000000):
        pass

Takeaways:
The with statement simplifies exception handling by encapsulating standard use of try/finally statements in a so called context managers.
Most commonly it is used to manage the safe acquisition and release of system resources. Resources are acquired by the with statement and released automatically when execution leaves the with context.
Using with effectively can help you avoid resource leaks and make your code easier to read.

Underscores, Dunders and More.
------------------------------
Single and Double underscores have a meaning in python variables and method. Some of that meaning is merely by convention and intended as a hint to the programmer and some of it is enforced by python interpreter.
There could be 5 types of variables or methods with underscores:
1. Single leading underscore - _var
2. Single trailing underscore - var_
3. Double leading underscores - __var
4. Double leading and trailing underscores - __var__
5. Single underscore - _

1. Single leading underscore - It has a meaning by convention, it is a hint to the programmer that the variable is private i.e it is used for internal purpose only.
The underscore prefix is meant as a hint to tell other programmers that a variable or method starting with a single underscore is intended for internal use. This convetion is defined in pep8 - https://pep8.org/
This convention is not enforced by python interpreter. Python does not have strong distinctions between private and public variables like Java does.
class Test:
    def __init__(self)
        self.foo = 11
        self._bar = 23

What's going to happen if you instantiate this class and try to access foo and _bar attributes defined in the constructor.
t = Test()
t.foo # 11
t._bar # 23
There was no difference.

But if you have a function named _func in a module and you imported that module as from module import * in that case _func will throw error.
“def external_func():
    return 23

“Now, if you use a wildcard import to import all the names from the module, Python will not import names with a leading underscore (unless the module defines an __all__ list that overrides this behavior):”

def _internal_func():
    return 42”
“>>> _internal_func()
NameError: "name '_internal_func' is not defined”

But importing the module as import module with not throw any error.
“>>> import my_module
>>> my_module.external_func()
23
>>> my_module._internal_func()
42”

Single Trailing Underscore:
---------------------------
Sometimes the most fitting name is already taken by the python keyword, in order to use same variable name as class_.

Double Leading Underscore:
--------------------------
“A double underscore prefix causes the Python interpreter to rewrite the attribute name in order to avoid naming conflicts in subclasses.”
“This is also called name mangling—the interpreter changes the name of the variable in a way that makes it harder to create collisions when the class is extended later.”
class Test:
    def __init__(self):
        self.foo = 11
        self._bar = 12
        self.__baz = 13
        
t = Test()
dir(t)
['_Test__baz','_bar', 'foo']
self.__baz is converted to _Test__baz

NameMangling
“If you look closely, you’ll see there’s an attribute called _Test__baz on this object. This is the name mangling that the Python interpreter applies. It does this to protect the variable from getting overridden in subclasses”

Now let's extend the Test class
    def __init__(self):
        super().__init__()
        self.foo = 'overriden'
        self._bar = 'overriden'
        self.__baz = 'overriden'
t2 = ETest()
print (t.foo, t2.foo) # 11 overriden
print (t._bar, t2._bar) # 11 overriden
print (t.__baz, t2.__baz) # AttributeError: 'Test' object has no attribute '__baz'

“As you can see, __baz got turned into _ExtendedTest__baz to prevent accidental modification. But the original _Test__baz is also still around:”
print (t._Test__baz, t2._ETest__baz) # 13 overriden

We can always use getter method to get the dunders(variables/methods) with double __
class ManglingTest:
    def __init__(self):
        self.__mangled = 'hello'
    def get_mangled(self):
        return self.__mangled
ManglingTest().get_mangled()


“Does name mangling also apply to method names? It sure does! Name mangling affects all names that start with two underscore characters (“dunders”) in a class context:”

