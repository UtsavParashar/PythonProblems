{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f29938",
   "metadata": {},
   "source": [
    "##### 126. Word Ladder II\n",
    "* https://leetcode.com/problems/word-ladder-ii/description/\n",
    "\n",
    "#### BBG - IMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be0c430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from typing import List\n",
    "from collections import deque,defaultdict\n",
    "class Solution:\n",
    "    def findLadders(self, begin_word: str, end_word: str, word_list: List[str]) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "            BFS + DFS(BT) solution\n",
    "            TC - O(N * L * 26)\n",
    "            SC - O(N * L)\n",
    "\n",
    "            Create a child-> parent implicit graph(DAG)\n",
    "            Maintain the level, shortest distance from root node in distance dict\n",
    "\n",
    "            Use queue for BFS traversal for form the graph\n",
    "            Use DFS to backtrack from last shortest path level to begin word\n",
    "\n",
    "            Remember - \n",
    "            1. Use found_end_word boolean to stop bfs as soon as the end word is found\n",
    "            2. Remember to continue if the ch is same as current_word[i] - does not make sense to get the same word(pattern)\n",
    "            3. Child can have multiple parents so remember to use the condition of\n",
    "            distance_dict[child_word] == current_distance + 1\n",
    "            4. Use visited set level to remove the words from wordset - pruning \n",
    "            5. After the graph is formed, check if the end word is present in the graph keys else return [] from there and DFS might not be required\n",
    "        \"\"\"\n",
    "        if end_word not in word_list:\n",
    "            return []\n",
    "\n",
    "        child_parent_graph = defaultdict(list)\n",
    "        level_distance_dict = {begin_word: 0} # word -> distance\n",
    "        \n",
    "        word_set = set(word_list)\n",
    "        found_end_word = False\n",
    "        \n",
    "        queue = deque([begin_word])\n",
    "        word_len = len(begin_word)\n",
    "        \n",
    "        # Step 1- BFS to form the implicit graph\n",
    "        while queue and not found_end_word:\n",
    "            level_size = len(queue)\n",
    "            \n",
    "\n",
    "            for _ in range(level_size):\n",
    "                visited_by_level = set()\n",
    "                curr_word = queue.popleft()\n",
    "                curr_distance = level_distance_dict[curr_word]\n",
    "\n",
    "                for i in range(word_len):\n",
    "                    for ch in string.ascii_lowercase:\n",
    "                        # This is equal to same word\n",
    "                        if ch == curr_word[i]:\n",
    "                            continue\n",
    "                        \n",
    "                        child_word = curr_word[:i] + ch + curr_word[i+1:]\n",
    "\n",
    "                        if child_word not in word_set:\n",
    "                            continue\n",
    "\n",
    "                        if child_word not in level_distance_dict:\n",
    "                            level_distance_dict[child_word] = curr_distance + 1\n",
    "                            child_parent_graph[child_word].append(curr_word)\n",
    "\n",
    "                            queue.append(child_word)\n",
    "                            visited_by_level.add(child_word)\n",
    "                        elif level_distance_dict[child_word] == curr_distance + 1:\n",
    "                            child_parent_graph[child_word].append(curr_word)\n",
    "\n",
    "                        if child_word == end_word:\n",
    "                            found_end_word = True\n",
    "            \n",
    "            word_set -= visited_by_level\n",
    "\n",
    "        if end_word not in child_parent_graph:\n",
    "            return []\n",
    "\n",
    "        # Step 2 - DFS(backtrack) from the end word to the begin word\n",
    "        res = [] \n",
    "        sol = [end_word]\n",
    "        def backtrack(child_word):\n",
    "            if child_word == begin_word:\n",
    "                res.append(sol[::-1])\n",
    "                return\n",
    "\n",
    "            for parent in child_parent_graph[child_word]:\n",
    "                sol.append(parent)\n",
    "                backtrack(parent)\n",
    "                sol.pop()\n",
    "\n",
    "        backtrack(end_word)\n",
    "        return res\n",
    "\n",
    "Solution().findLadders(begin_word = \"hit\", end_word = \"cog\", word_list = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
